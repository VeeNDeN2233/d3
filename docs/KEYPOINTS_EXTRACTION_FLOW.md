# –ü—Ä–æ—Ü–µ—Å—Å –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫ –∏–∑ –≤–∏–¥–µ–æ

## üìπ –ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ

### –®–∞–≥ 1: –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ —á–µ—Ä–µ–∑ MediaPipe (`video_processor.py`)

```python
# –í –º–µ—Ç–æ–¥–µ _process_video_sync():

# 1. –û—Ç–∫—Ä—ã–≤–∞–µ–º –≤–∏–¥–µ–æ
cap = cv2.VideoCapture(input_path)

# 2. –î–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–∞–¥—Ä–∞:
while True:
    ok, frame_bgr = cap.read()
    if not ok:
        break
    
    # 3. –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º BGR ‚Üí RGB (MediaPipe —Ç—Ä–µ–±—É–µ—Ç RGB)
    frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)
    
    # 4. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —á–µ—Ä–µ–∑ MediaPipe Pose
    results = self._pose.process(frame_rgb)
    # results.pose_landmarks - —ç—Ç–æ –æ–±—ä–µ–∫—Ç —Å 33 —Ç–æ—á–∫–∞–º–∏ MediaPipe
    
    # 5. –°–æ—Ö—Ä–∞–Ω—è–µ–º landmarks –≤ —Å–ø–∏—Å–æ–∫
    if save_keypoints:
        all_keypoints.append({
            "frame": frames_processed,
            "landmarks": self._landmarks_to_list(results.pose_landmarks),
            "mini_rgbd": mini_rgbd_joints,
        })
```

### –®–∞–≥ 2: –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è landmarks –≤ —Å–ø–∏—Å–æ–∫ (`_landmarks_to_list`)

```python
def _landmarks_to_list(self, pose_landmarks) -> Optional[List[Dict[str, float]]]:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç MediaPipe landmarks –≤ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π."""
    if pose_landmarks is None:
        return None
    
    out = []
    for lm in pose_landmarks.landmark:
        out.append({
            "x": float(lm.x),      # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞ [0, 1]
            "y": float(lm.y),      # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞ [0, 1]
            "z": float(lm.z),      # –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–∞—è –≥–ª—É–±–∏–Ω–∞
            "visibility": float(getattr(lm, "visibility", 0.0)),  # –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å [0, 1]
        })
    return out
```

**–í–∞–∂–Ω–æ:** MediaPipe –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤ **–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ [0, 1]**, –≥–¥–µ:
- `x = 0.0` - –ª–µ–≤—ã–π –∫—Ä–∞–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
- `x = 1.0` - –ø—Ä–∞–≤—ã–π –∫—Ä–∞–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
- `y = 0.0` - –≤–µ—Ä—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
- `y = 1.0` - –Ω–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è

### –®–∞–≥ 3: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ JSON (`_save_keypoints`)

```python
# –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ keypoints/keypoints.json:
{
    "format": "mini_rgbd",
    "source": "mediapipe_pose",
    "joints": 25,
    "video": {
        "width": 856,
        "height": 472,
        "fps": 29.92,
        "frames": 91
    },
    "frames": [
        {
            "frame": 0,
            "landmarks": [
                {"x": 0.7965, "y": 0.4762, "z": -0.1234, "visibility": 0.98},
                ...
            ],
            "mini_rgbd": [...]
        },
        ...
    ]
}
```

### –®–∞–≥ 4: –ó–∞–≥—Ä—É–∑–∫–∞ keypoints –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (`inference_advanced.py`)

```python
# –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ JSON
keypoints_path = Path(result["keypoints_path"]) / "keypoints.json"
with open(keypoints_path, "r") as f:
    keypoints_data = json.load(f)

# –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ numpy –º–∞—Å—Å–∏–≤—ã
keypoints_list = []
for frame_data in keypoints_data["frames"]:
    landmarks = frame_data.get("landmarks")
    if landmarks:
        kp = np.array(
            [[lm["x"], lm["y"], lm["z"], lm.get("visibility", 0.0)] 
             for lm in landmarks],
            dtype=np.float32,
        )
        keypoints_list.append(kp)  # (33, 4) - 33 —Ç–æ—á–∫–∏ √ó 4 –∑–Ω–∞—á–µ–Ω–∏—è
    else:
        keypoints_list.append(None)
```

### –®–∞–≥ 5: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ keypoints –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏

–¢–µ–ø–µ—Ä—å `keypoints_list` —Å–æ–¥–µ—Ä–∂–∏—Ç:
- **–§–æ—Ä–º–∞—Ç:** —Å–ø–∏—Å–æ–∫ numpy –º–∞—Å—Å–∏–≤–æ–≤ —Ñ–æ—Ä–º—ã `(33, 4)`
- **–ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã:** –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ [0, 1] –∏–∑ MediaPipe
- **–°—Ç—Ä—É–∫—Ç—É—Ä–∞:** `[x, y, z, visibility]` –¥–ª—è –∫–∞–∂–¥–æ–π –∏–∑ 33 —Ç–æ—á–µ–∫

–î–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –Ω—É–∂–Ω–æ:
1. –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤ –ø–∏–∫—Å–µ–ª–∏: `x_pixel = x_norm * width`
2. –ù–∞—Ä–∏—Å–æ–≤–∞—Ç—å —Ç–æ—á–∫–∏ –∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —á–µ—Ä–µ–∑ OpenCV

## üîÑ –ü–æ–ª–Ω—ã–π –ø–æ—Ç–æ–∫ –¥–∞–Ω–Ω—ã—Ö

```
–í–∏–¥–µ–æ (baby.mp4)
    ‚Üì
VideoProcessor._process_video_sync()
    ‚Üì
MediaPipe Pose.process(frame_rgb)
    ‚Üì
results.pose_landmarks (33 —Ç–æ—á–∫–∏, –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ [0, 1])
    ‚Üì
_landmarks_to_list() ‚Üí List[Dict[x, y, z, visibility]]
    ‚Üì
_save_keypoints() ‚Üí keypoints/keypoints.json
    ‚Üì
inference_advanced.process_video()
    ‚Üì
–ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑ JSON ‚Üí keypoints_list: List[np.ndarray(33, 4)]
    ‚Üì
create_skeleton_video_from_processed()
    ‚Üì
–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ [0, 1] ‚Üí –ø–∏–∫—Å–µ–ª–∏ ‚Üí —Ä–∏—Å–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ OpenCV
    ‚Üì
–í–∏–¥–µ–æ —Å –Ω–∞–ª–æ–∂–µ–Ω–Ω—ã–º —Å–∫–µ–ª–µ—Ç–æ–º
```

## üìä –§–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –∫–∞–∂–¥–æ–º —ç—Ç–∞–ø–µ

1. **MediaPipe —Ä–µ–∑—É–ª—å—Ç–∞—Ç:** `results.pose_landmarks` - protobuf –æ–±—ä–µ–∫—Ç —Å 33 landmarks
2. **JSON —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ:** `{"x": 0.7965, "y": 0.4762, "z": -0.1234, "visibility": 0.98}`
3. **Numpy –º–∞—Å—Å–∏–≤:** `np.array([[x, y, z, visibility], ...])` —Ñ–æ—Ä–º–∞ `(33, 4)`
4. **–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è:** –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ –ø–∏–∫—Å–µ–ª–∏ –∏ —Ä–∏—Å–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ OpenCV

## ‚úÖ –í–∞–∂–Ω–æ –ø–æ–º–Ω–∏—Ç—å

- **–ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤—Å–µ–≥–¥–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ [0, 1]** –Ω–∞ —ç—Ç–∞–ø–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
- **–î–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –Ω—É–∂–Ω–æ —É–º–Ω–æ–∂–∏—Ç—å –Ω–∞ width/height** —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –ø–∏–∫—Å–µ–ª–∏
- **MediaPipe –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∫–∞–∂–¥—ã–π –∫–∞–¥—Ä –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ** - –Ω–µ—Ç —Å–≤—è–∑–∏ –º–µ–∂–¥—É –∫–∞–¥—Ä–∞–º–∏
- **33 —Ç–æ—á–∫–∏ MediaPipe** —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º—É –Ω–∞–±–æ—Ä—É landmarks –¥–ª—è —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–π –ø–æ–∑—ã

