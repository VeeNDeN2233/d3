"""
Ğ˜Ğ½Ñ„ĞµÑ€ĞµĞ½Ñ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ´Ğ²Ğ¸Ğ½ÑƒÑ‚Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ (Bidirectional LSTM + Attention).
"""

import argparse
import json
import logging
from pathlib import Path
from typing import Dict, List, Optional, Tuple

import cv2
import matplotlib.pyplot as plt
import numpy as np
import torch
import torch.nn as nn
import yaml

from models.anomaly_detector import AnomalyDetector
from models.autoencoder_advanced import BidirectionalLSTMAutoencoder
from utils.pose_processor import PoseProcessor
from video_processor import VideoProcessor

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)


def load_model_and_detector(
    checkpoint_path: Path, config: dict, device: torch.device, model_type: str = "bidir_lstm"
) -> Tuple[nn.Module, AnomalyDetector]:
    """
    Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ğ¿Ñ€Ğ¾Ğ´Ğ²Ğ¸Ğ½ÑƒÑ‚ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ¸ Ğ´ĞµÑ‚ĞµĞºÑ‚Ğ¾Ñ€ Ğ¸Ğ· checkpoint.
    
    Args:
        checkpoint_path: ĞŸÑƒÑ‚ÑŒ Ğº checkpoint
        config: ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
        device: Ğ£ÑÑ‚Ñ€Ğ¾Ğ¹ÑÑ‚Ğ²Ğ¾ (GPU)
        model_type: Ğ¢Ğ¸Ğ¿ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ ("bidir_lstm" Ğ¸Ğ»Ğ¸ "transformer")
    
    Returns:
        Tuple (model, detector)
    """
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ
    if model_type == "bidir_lstm":
        model = BidirectionalLSTMAutoencoder(
            input_size=config["model"]["input_size"],
            sequence_length=config["pose"]["sequence_length"],
            encoder_hidden_sizes=[256, 128, 64],
            decoder_hidden_sizes=[64, 128, 256, 75],
            latent_size=64,
            num_attention_heads=4,
            dropout=0.2,
        ).to(device)
    else:
        raise ValueError(f"ĞœĞ¾Ğ´ĞµĞ»ÑŒ {model_type} Ğ½Ğµ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµÑ‚ÑÑ")
    
    # Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ğ²ĞµÑĞ°
    checkpoint = torch.load(checkpoint_path, map_location=device)
    model.load_state_dict(checkpoint["model_state_dict"])
    model.eval()
    
    logger.info(f"ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ° Ğ¸Ğ· {checkpoint_path}")
    
    # Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ğ´ĞµÑ‚ĞµĞºÑ‚Ğ¾Ñ€
    detector_path = checkpoint_path.parent / "anomaly_detector_advanced.pt"
    if not detector_path.exists():
        raise FileNotFoundError(f"Ğ”ĞµÑ‚ĞµĞºÑ‚Ğ¾Ñ€ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½: {detector_path}")
    
    detector = AnomalyDetector.load(detector_path, model, device)
    
    logger.info(f"Ğ”ĞµÑ‚ĞµĞºÑ‚Ğ¾Ñ€ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½ Ğ¸Ğ· {detector_path}")
    logger.info(f"ĞŸĞ¾Ñ€Ğ¾Ğ³ Ğ°Ğ½Ğ¾Ğ¼Ğ°Ğ»Ğ¸Ğ¸: {detector.threshold:.6f}")
    
    return model, detector


def process_video(
    video_path: Path,
    video_processor: VideoProcessor,
    pose_processor: PoseProcessor,
    detector: AnomalyDetector,
    config: dict,
) -> Tuple[List[np.ndarray], List[float], List[bool], np.ndarray]:
    """ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ Ğ²Ğ¸Ğ´ĞµĞ¾ Ğ¸ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ Ğ°Ğ½Ğ¾Ğ¼Ğ°Ğ»Ğ¸Ğ¹."""
    logger.info(f"ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ²Ğ¸Ğ´ĞµĞ¾: {video_path}")
    
    temp_output = video_path.parent / f"temp_{video_path.name}"
    
    result = video_processor._process_video_sync(
        str(video_path), str(temp_output), save_keypoints=True
    )
    
    if not result["success"]:
        raise RuntimeError(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ²Ğ¸Ğ´ĞµĞ¾: {result.get('error')}")
    
    # Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ñ‚Ğ¾Ñ‡ĞºĞ¸
    keypoints_path = Path(result["keypoints_path"]) / "keypoints.json"
    with open(keypoints_path, "r", encoding="utf-8") as f:
        keypoints_data = json.load(f)
    
    # Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ñ‚Ğ¾Ñ‡ĞºĞ¸
    keypoints_list = []
    for frame_data in keypoints_data["frames"]:
        landmarks = frame_data.get("landmarks")
        if landmarks:
            kp = np.array(
                [[lm["x"], lm["y"], lm["z"], lm.get("visibility", 0.0)] for lm in landmarks],
                dtype=np.float32,
            )
            keypoints_list.append(kp)
        else:
            keypoints_list.append(None)
    
    # ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµĞ¼ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ñ‚Ğ¾Ñ‡ĞºĞ¸
    sequences = pose_processor.process_keypoints(keypoints_list)
    
    if len(sequences) == 0:
        logger.warning("ĞĞµÑ‚ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ñ… Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ĞµĞ¹")
        return keypoints_list, [], []
    
    # ĞŸÑ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·ÑƒĞµĞ¼ Ğ² Ğ¿Ğ»Ğ¾ÑĞºĞ¸Ğµ Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ñ‹
    flattened_sequences = [pose_processor.flatten_sequence(seq) for seq in sequences]
    sequences_array = np.array(flattened_sequences)  # (N, 30, 75)
    sequences_tensor = torch.FloatTensor(sequences_array)
    
    # ĞŸÑ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğµ Ğ°Ğ½Ğ¾Ğ¼Ğ°Ğ»Ğ¸Ğ¹
    is_anomaly, errors = detector.predict(sequences_tensor.to(detector.device))
    
    # Ğ£Ğ´Ğ°Ğ»ÑĞµĞ¼ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğ¹ Ñ„Ğ°Ğ¹Ğ»
    if temp_output.exists():
        temp_output.unlink()
    
    return keypoints_list, errors.tolist(), is_anomaly.tolist(), sequences_array


def visualize_results(
    errors: List[float],
    is_anomaly: List[bool],
    output_dir: Path,
    video_name: str,
    threshold: Optional[float] = None,
) -> Dict[str, Path]:
    """Ğ’Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²."""
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # Ğ“Ñ€Ğ°Ñ„Ğ¸Ğº Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸ Ñ€ĞµĞºĞ¾Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ğ¸
    fig, ax = plt.subplots(figsize=(12, 6))
    frames = np.arange(len(errors))
    ax.plot(frames, errors, label="Reconstruction Error", linewidth=2, color="blue")
    
    # ĞŸĞ¾Ñ€Ğ¾Ğ³ Ğ°Ğ½Ğ¾Ğ¼Ğ°Ğ»Ğ¸Ğ¸
    if threshold is not None:
        ax.axhline(y=threshold, color="r", linestyle="--", label=f"Anomaly Threshold ({threshold:.4f})", linewidth=2)
    
    # ĞŸĞ¾Ğ¼ĞµÑ‡Ğ°ĞµĞ¼ Ğ°Ğ½Ğ¾Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸
    anomaly_frames = [i for i, is_anom in enumerate(is_anomaly) if is_anom]
    if anomaly_frames:
        ax.scatter(anomaly_frames, [errors[i] for i in anomaly_frames], 
                  color="red", s=50, label="Anomalous", zorder=5)
    
    ax.set_xlabel("Sequence Index", fontsize=12)
    ax.set_ylabel("Reconstruction Error (MSE)", fontsize=12)
    ax.set_title(f"Reconstruction Error Over Time - {video_name}", fontsize=14)
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    error_plot_path = output_dir / "reconstruction_error.png"
    plt.savefig(error_plot_path, dpi=300, bbox_inches="tight")
    plt.close()
    
    logger.info(f"Ğ“Ñ€Ğ°Ñ„Ğ¸Ğº ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½: {error_plot_path}")
    
    return {"error_plot": error_plot_path}


def generate_report(
    video_path: Path,
    errors: List[float],
    is_anomaly: List[bool],
    detector: AnomalyDetector,
    output_dir: Path,
    age_weeks: Optional[float] = None,
    gestational_age_weeks: Optional[float] = None,
    sequences_array: Optional[np.ndarray] = None,
) -> Dict:
    """Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¼ĞµĞ´Ğ¸Ñ†Ğ¸Ğ½ÑĞºĞ¾Ğ³Ğ¾ Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ° Ğ² Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ GMA."""
    if len(errors) == 0:
        return {}
    
    errors_array = np.array(errors)
    anomaly_rate = np.mean(is_anomaly) * 100
    
    # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ ÑƒÑ€Ğ¾Ğ²ĞµĞ½ÑŒ Ñ€Ğ¸ÑĞºĞ° Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ GMA ĞºÑ€Ğ¸Ñ‚ĞµÑ€Ğ¸ĞµĞ²
    mean_error = float(errors_array.mean())
    
    # GMA ĞºÑ€Ğ¸Ñ‚ĞµÑ€Ğ¸Ğ¸ Ñ€Ğ¸ÑĞºĞ°
    if mean_error > detector.threshold * 1.5:
        risk_level = "high"
        gma_assessment = "ĞĞĞĞœĞĞ›Ğ¬ĞĞ«Ğ• Ğ¾Ğ±Ñ‰Ğ¸Ğµ Ğ´Ğ²Ğ¸Ğ¶ĞµĞ½Ğ¸Ñ"
        cp_risk = "Ğ’Ğ«Ğ¡ĞĞšĞ˜Ğ™ Ñ€Ğ¸ÑĞº Ñ†ĞµÑ€ĞµĞ±Ñ€Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ¸Ñ‡Ğ°"
    elif mean_error > detector.threshold:
        risk_level = "medium"
        gma_assessment = "ĞŸĞĞ”ĞĞ—Ğ Ğ˜Ğ¢Ğ•Ğ›Ğ¬ĞĞ«Ğ• Ğ¾Ğ±Ñ‰Ğ¸Ğµ Ğ´Ğ²Ğ¸Ğ¶ĞµĞ½Ğ¸Ñ"
        cp_risk = "Ğ£ĞœĞ•Ğ Ğ•ĞĞĞ«Ğ™ Ñ€Ğ¸ÑĞº Ğ½ĞµĞ²Ñ€Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğ¹"
    else:
        risk_level = "low"
        gma_assessment = "ĞĞĞ ĞœĞĞ›Ğ¬ĞĞ«Ğ• Ğ¾Ğ±Ñ‰Ğ¸Ğµ Ğ´Ğ²Ğ¸Ğ¶ĞµĞ½Ğ¸Ñ"
        cp_risk = "ĞĞ˜Ğ—ĞšĞ˜Ğ™ Ñ€Ğ¸ÑĞº"
    
    # Ğ”ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ°Ğ½Ğ¾Ğ¼Ğ°Ğ»Ğ¸Ğ¹ Ğ¿Ğ¾ ÑÑƒÑÑ‚Ğ°Ğ²Ğ°Ğ¼
    detailed_analysis = {}
    if sequences_array is not None and len(sequences_array) > 0 and risk_level != "low":
        try:
            from utils.anomaly_analyzer import analyze_joint_errors
            
            sequences_np = np.array(sequences_array)
            errors_np = np.array(errors)
            
            detailed_analysis = analyze_joint_errors(
                sequences_np,
                errors_np,
                detector.threshold
            )
        except Exception as e:
            logger.warning(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°: {e}")
            detailed_analysis = {}
    
    # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¸ Ğ°Ğ½Ğ¾Ğ¼Ğ°Ğ»Ğ¸Ğ¹ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°
    detected_signs = []
    if detailed_analysis.get("has_anomalies", False):
        # ĞÑĞ¸Ğ¼Ğ¼ĞµÑ‚Ñ€Ğ¸Ñ
        asymmetry = detailed_analysis.get("asymmetry", {})
        if asymmetry.get("has_asymmetry", False):
            for finding in asymmetry.get("findings", []):
                detected_signs.append(finding["description"])
        
        # ĞĞ½Ğ°Ğ»Ğ¸Ğ· ÑÑƒÑÑ‚Ğ°Ğ²Ğ¾Ğ²
        joint_analysis = detailed_analysis.get("joint_analysis", {})
        for finding in joint_analysis.get("findings", []):
            if finding["type"] == "reduced_movement":
                detected_signs.append(finding["description"])
            elif finding["type"] == "high_speed":
                detected_signs.append(finding["description"])
        
        # Ğ¡ĞºĞ¾Ñ€Ğ¾ÑÑ‚ÑŒ Ğ´Ğ²Ğ¸Ğ¶ĞµĞ½Ğ¸Ğ¹
        speed_analysis = detailed_analysis.get("speed_analysis", {})
        for finding in speed_analysis.get("findings", []):
            detected_signs.append(finding["description"])
        
        # ĞĞ¼Ğ¿Ğ»Ğ¸Ñ‚ÑƒĞ´Ğ° Ğ´Ğ²Ğ¸Ğ¶ĞµĞ½Ğ¸Ğ¹
        amplitude_analysis = detailed_analysis.get("amplitude_analysis", {})
        for finding in amplitude_analysis.get("findings", []):
            detected_signs.append(finding["description"])
    
    # Fallback ĞµÑĞ»Ğ¸ Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½
    if len(detected_signs) == 0:
        if anomaly_rate > 30:
            detected_signs.append("Ğ²Ñ‹ÑĞ¾ĞºĞ°Ñ Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ğ° Ğ°Ğ½Ğ¾Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ğ¾Ğ²")
        if mean_error > detector.threshold * 1.2:
            detected_signs.append("ÑĞ½Ğ¸Ğ¶ĞµĞ½Ğ½Ğ°Ñ Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ±ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ´Ğ²Ğ¸Ğ¶ĞµĞ½Ğ¸Ğ¹")
        if len(detected_signs) == 0 and risk_level != "low":
            detected_signs.append("Ğ¾Ñ‚ĞºĞ»Ğ¾Ğ½ĞµĞ½Ğ¸Ñ Ğ¾Ñ‚ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ğ¾Ğ²")
    
    # Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ GMA
    recommendations = []
    if risk_level == "low":
        recommendations.append("âœ… Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ñ: ĞŸĞ»Ğ°Ğ½Ğ¾Ğ²Ğ°Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ° Ğ² 4 Ğ¼ĞµÑÑÑ†Ğ°")
        recommendations.append("ĞŸÑ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ¸Ñ‚ÑŒ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ğ¾Ğµ Ğ½Ğ°Ğ±Ğ»ÑĞ´ĞµĞ½Ğ¸Ğµ")
    elif risk_level == "medium":
        recommendations.append("âš ï¸ Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ñ: ĞŸĞ¾Ğ²Ñ‚Ğ¾Ñ€Ğ½Ğ°Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ° Ñ‡ĞµÑ€ĞµĞ· 2-4 Ğ½ĞµĞ´ĞµĞ»Ğ¸")
        recommendations.append("ĞĞ°Ğ±Ğ»ÑĞ´ĞµĞ½Ğ¸Ğµ Ñƒ Ğ¿ĞµĞ´Ğ¸Ğ°Ñ‚Ñ€Ğ°")
    else:  # high
        recommendations.append("ğŸ”´ Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ñ: Ğ¡Ğ ĞĞ§ĞĞĞ¯ ĞºĞ¾Ğ½ÑÑƒĞ»ÑŒÑ‚Ğ°Ñ†Ğ¸Ñ Ğ´ĞµÑ‚ÑĞºĞ¾Ğ³Ğ¾ Ğ½ĞµĞ²Ñ€Ğ¾Ğ»Ğ¾Ğ³Ğ°")
        recommendations.append("ĞĞ°Ñ‡Ğ°Ñ‚ÑŒ Ñ€Ğ°Ğ½Ğ½ĞµĞµ Ğ²Ğ¼ĞµÑˆĞ°Ñ‚ĞµĞ»ÑŒÑÑ‚Ğ²Ğ¾")
        if detected_signs:
            recommendations.append(f"Ğ’Ñ‹ÑĞ²Ğ»ĞµĞ½Ñ‹ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¸: {', '.join(detected_signs)}")
    
    # Ğ˜Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾ Ğ²Ğ¾Ğ·Ñ€Ğ°ÑÑ‚Ğµ
    age_info = {}
    if age_weeks is not None:
        age_info["age_weeks"] = float(age_weeks)
        if age_weeks >= 9 and age_weeks <= 20:
            age_info["period"] = "ĞŸĞµÑ€Ğ¸Ğ¾Ğ´ ÑÑƒĞµÑ‚Ğ»Ğ¸Ğ²Ñ‹Ñ… Ğ´Ğ²Ğ¸Ğ¶ĞµĞ½Ğ¸Ğ¹ (fidgety movements)"
        elif age_weeks < 9:
            age_info["period"] = "Ğ Ğ°Ğ½Ğ½Ğ¸Ğ¹ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´ (writhing movements)"
        else:
            age_info["period"] = "ĞŸĞ¾Ğ·Ğ´Ğ½Ğ¸Ğ¹ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´"
    
    if gestational_age_weeks is not None:
        age_info["gestational_age_weeks"] = float(gestational_age_weeks)
        if gestational_age_weeks < 37:
            age_info["premature"] = True
            age_info["corrected_age"] = age_weeks - (40 - gestational_age_weeks) if age_weeks else None
    
    report = {
        "video_path": str(video_path),
        "analysis_date": str(Path.cwd()),
        "gma_assessment": {
            "assessment_result": gma_assessment,
            "risk_level": risk_level.upper(),
            "cp_risk": cp_risk,
            "detected_signs": detected_signs,
        },
        "patient_info": age_info,
        "statistics": {
            "total_sequences": len(errors),
            "anomalous_sequences": sum(is_anomaly),
            "anomaly_rate": anomaly_rate,
        },
        "reconstruction_errors": {
            "mean": float(errors_array.mean()),
            "max": float(errors_array.max()),
            "min": float(errors_array.min()),
            "std": float(errors_array.std()),
        },
        "anomaly_detection": {
            "threshold": float(detector.threshold),
            "mean_anomaly_score": mean_error,
            "risk_level": risk_level,
            "anomaly_rate_percent": anomaly_rate,
        },
        "recommendations": recommendations,
        "detailed_analysis": detailed_analysis,
    }
    
    # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ¾Ñ‚Ñ‡ĞµÑ‚
    report_path = output_dir / "medical_report.json"
    with open(report_path, "w", encoding="utf-8") as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    logger.info(f"ĞÑ‚Ñ‡ĞµÑ‚ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½: {report_path}")
    
    return report


def main():
    parser = argparse.ArgumentParser(description="Ğ˜Ğ½Ñ„ĞµÑ€ĞµĞ½Ñ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ´Ğ²Ğ¸Ğ½ÑƒÑ‚Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸")
    parser.add_argument("--video", type=str, required=True, help="ĞŸÑƒÑ‚ÑŒ Ğº Ğ²Ğ¸Ğ´ĞµĞ¾")
    parser.add_argument("--checkpoint", type=str, default="checkpoints/best_model_advanced.pt",
                       help="ĞŸÑƒÑ‚ÑŒ Ğº checkpoint")
    parser.add_argument("--config", type=str, default="config.yaml", help="ĞŸÑƒÑ‚ÑŒ Ğº ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸")
    parser.add_argument("--output", type=str, help="ĞŸÑƒÑ‚ÑŒ Ğ´Ğ»Ñ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²")
    parser.add_argument("--save_report", action="store_true", help="Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ Ğ¾Ñ‚Ñ‡ĞµÑ‚")
    parser.add_argument("--model_type", type=str, default="bidir_lstm", 
                       choices=["bidir_lstm", "transformer"], help="Ğ¢Ğ¸Ğ¿ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸")
    
    args = parser.parse_args()
    
    # Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ
    with open(args.config, "r", encoding="utf-8") as f:
        config = yaml.safe_load(f)
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ GPU
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    if device.type != "cuda":
        raise RuntimeError("Ğ¢Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ GPU Ğ´Ğ»Ñ Ğ¸Ğ½Ñ„ĞµÑ€ĞµĞ½ÑĞ°!")
    
    logger.info(f"Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ ÑƒÑÑ‚Ñ€Ğ¾Ğ¹ÑÑ‚Ğ²Ğ¾: {device}")
    
    # Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ¸ Ğ´ĞµÑ‚ĞµĞºÑ‚Ğ¾Ñ€
    checkpoint_path = Path(args.checkpoint)
    model, detector = load_model_and_detector(checkpoint_path, config, device, args.model_type)
    
    # Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ¾Ñ€Ğ¾Ğ²
    video_processor = VideoProcessor(
        model_complexity=config["pose"]["model_complexity"],
        min_detection_confidence=config["pose"]["min_detection_confidence"],
        min_tracking_confidence=config["pose"]["min_tracking_confidence"],
    )
    
    pose_processor = PoseProcessor(
        sequence_length=config["pose"]["sequence_length"],
        sequence_stride=config["pose"]["sequence_stride"],
        normalize=config["pose"]["normalize"],
        normalize_relative_to=config["pose"]["normalize_relative_to"],
        target_hip_distance=config["pose"].get("target_hip_distance"),
        normalize_by_body=config["pose"].get("normalize_by_body", False),
        rotate_to_canonical=config["pose"].get("rotate_to_canonical", False),
    )
    
    # ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ²Ğ¸Ğ´ĞµĞ¾
    video_path = Path(args.video)
    keypoints_list, errors, is_anomaly = process_video(
        video_path, video_processor, pose_processor, detector, config
    )
    
    # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ´Ğ»Ñ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²
    if args.output:
        output_dir = Path(args.output)
    else:
        output_dir = Path("results") / video_path.stem
    
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # Ğ’Ğ¸Ğ·ÑƒĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ
    visualize_results(errors, is_anomaly, output_dir, video_path.stem, detector.threshold)
    
    # Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾Ñ‚Ñ‡ĞµÑ‚Ğ°
    if args.save_report:
        report = generate_report(video_path, errors, is_anomaly, detector, output_dir)
        
        logger.info("=" * 60)
        logger.info("Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢Ğ« ĞĞĞĞ›Ğ˜Ğ—Ğ")
        logger.info("=" * 60)
        logger.info(f"Ğ£Ñ€Ğ¾Ğ²ĞµĞ½ÑŒ Ñ€Ğ¸ÑĞºĞ°: {report['anomaly_detection']['risk_level'].upper()}")
        logger.info(f"ĞĞ½Ğ¾Ğ¼Ğ°Ğ»Ğ¸Ğ¹: {report['anomaly_detection']['anomaly_rate_percent']:.2f}%")
        logger.info(f"Ğ¡Ñ€ĞµĞ´Ğ½ÑÑ Ğ¾ÑˆĞ¸Ğ±ĞºĞ°: {report['reconstruction_errors']['mean']:.6f}")
        logger.info(f"ĞŸĞ¾Ñ€Ğ¾Ğ³: {report['anomaly_detection']['threshold']:.6f}")
    
    logger.info(f"Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ñ‹ Ğ²: {output_dir}")


if __name__ == "__main__":
    main()

